{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKu-sCJWBAE6"
      },
      "source": [
        "# Deep Generative Replay for Continual Learning on MNIST\n",
        "### Assignment for the **Deep Generative View on Continual Learning** course.\n",
        "\n",
        "Student Names: __Andrea Giuseppe Di Francesco__ and __Farooq Ahmad Wani__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UQgyyPdBa_k"
      },
      "source": [
        "*The following code is inspired from the notebooks viewed during the course's lessons, and the openly available [notebook on GAN for MNIST](https://github.com/lyeoni/pytorch-mnist-GAN/blob/master/pytorch-mnist-GAN.ipynb)*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGN5M68NAhRA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from torch.utils.data import Subset, TensorDataset, DataLoader\n",
        "from random import shuffle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "import psutil\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    raise SystemError(\"GPU device not found, selection Runtime -> Change runtime type\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aON2TPJzAhRB"
      },
      "source": [
        "### Arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlpmG_SiAhRB"
      },
      "outputs": [],
      "source": [
        "\n",
        "args = {\n",
        "    'lr': 1e-2,                   \n",
        "    'lr_generator': 0.0002,            \n",
        "    'lr_discriminator': 0.00002,     \n",
        "    'bs': 128,                   \n",
        "    'epochs': 20,                 \n",
        "    'num_tasks': 5,         \n",
        "    'epochs_gan': 20,            \n",
        "    'dataset': \"MNIST\",          \n",
        "    'num_classes': 10,          \n",
        "    'in_size': 28,               \n",
        "    'n_channels': 1,             \n",
        "    'hidden_size': 50,         \n",
        "    'g_input_dim': 100,           \n",
        "    'g_output_dim': 784,         \n",
        "    'ratio': 0.7\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMjlOki_AhRB"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJpKBdbwAhRB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_dataset(dataroot, dataset):\n",
        "    if dataset == 'MNIST':\n",
        "        mean, std = (0.1307), (0.3081)\n",
        "    elif dataset == 'CIFAR10':\n",
        "        mean, std = (0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)\n",
        "\n",
        "    transform = torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor(),\n",
        "        torchvision.transforms.Normalize(mean=mean, std=std)])\n",
        "\n",
        "    train_dataset = torchvision.datasets.__dict__[dataset](\n",
        "        root=dataroot,\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    val_dataset = torchvision.datasets.__dict__[dataset](\n",
        "        root=dataroot,\n",
        "        train=False,\n",
        "        download=True,\n",
        "        transform=transform\n",
        "    )\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n",
        "def split_dataset(dataset, tasks_split):\n",
        "    split_dataset = {}\n",
        "    for e, current_classes in tasks_split.items():\n",
        "        task_indices = np.isin(np.array(dataset.targets), current_classes)\n",
        "        split_dataset[e] = Subset(dataset, np.where(task_indices)[0])\n",
        "    return split_dataset\n",
        "\n",
        "def set_random_seed(seed):\n",
        "    random.seed(seed)\n",
        "\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x6md_1PAhRC"
      },
      "source": [
        "### Metrics & plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajC1EnwTAhRC"
      },
      "outputs": [],
      "source": [
        "def dict2array(acc):\n",
        "    num_tasks = len(acc)\n",
        "    first_task = list(acc.keys())[0]\n",
        "    sequence_length = len(acc[first_task]) if isinstance(acc[first_task], list) else num_tasks\n",
        "    acc_array = np.zeros((num_tasks, sequence_length))\n",
        "    for task, val in acc.items():\n",
        "        acc_array[int(task), :] = val\n",
        "    return acc_array\n",
        "\n",
        "\n",
        "def plot_accuracy_matrix(array):\n",
        "    num_tasks = array.shape[1]\n",
        "    array = np.round(array, 2)\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(array, vmin=np.min(array), vmax=np.max(array))\n",
        "    for i in range(len(array)):\n",
        "        for j in range(array.shape[1]):\n",
        "            ax.text(j,i, array[i,j], va='center', ha='center', c='w', fontsize=15)\n",
        "    ax.set_yticks(np.arange(num_tasks))\n",
        "    ax.set_ylabel('Number of tasks')\n",
        "    ax.set_xticks(np.arange(num_tasks))\n",
        "    ax.set_xlabel('Tasks finished')\n",
        "    ax.set_title(f\"ACC: {np.mean(array[:, -1]):.3f} -- std {np.std(np.mean(array[:, -1])):.3f}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_acc_over_time(array):\n",
        "    fig, ax = plt.subplots()\n",
        "    for e, acc in enumerate(array):\n",
        "        ax.plot(acc, label=e)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def compute_average_accuracy(array):\n",
        "    num_tasks = len(array)\n",
        "    avg_acc = np.sum(array[:, -1], axis=0)/num_tasks\n",
        "    return avg_acc\n",
        "\n",
        "\n",
        "def compute_backward_transfer(array):\n",
        "    num_tasks = len(array)\n",
        "    diag = np.diag(array)[:-1] # Note, we do not compute backward transfer for the last task!\n",
        "    end_acc = array[:-1, -1]\n",
        "    bwt = np.sum(end_acc - diag)/(num_tasks - 1)\n",
        "    return bwt\n",
        "\n",
        "\n",
        "def compute_forward_transfer(array, b):\n",
        "    num_tasks = len(array)\n",
        "    sub_diag = np.diag(array, k=-1) # Note, we do not compute forward transfer for the first task!\n",
        "    fwt = np.sum(sub_diag - b[1:])/(num_tasks - 1)\n",
        "    return fwt\n",
        "\n",
        "def print_memory_usage():\n",
        "    # RAM usage\n",
        "    ram_usage = psutil.virtual_memory().used / (1024 ** 3)  # Convert bytes to GB\n",
        "    print(f\"RAM Usage: {ram_usage:.2f} GB\")\n",
        "    \n",
        "    # GPU usage\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_allocated = torch.cuda.memory_allocated() / (1024 ** 3)  # Convert bytes to GB\n",
        "        gpu_memory_reserved = torch.cuda.memory_reserved() / (1024 ** 3)    # Convert bytes to GB\n",
        "        print(f\"GPU Memory Allocated: {gpu_memory_allocated:.2f} GB\")\n",
        "        print(f\"GPU Memory Reserved: {gpu_memory_reserved:.2f} GB\")\n",
        "    else:\n",
        "        print(\"CUDA is not available.\")\n",
        "\n",
        "        \n",
        "def get_n_params(model):\n",
        "    pp=0\n",
        "    for p in list(model.parameters()):\n",
        "        nn=1\n",
        "        for s in list(p.size()):\n",
        "            nn = nn*s\n",
        "        pp += nn\n",
        "    return pp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-4M8R3xEB1s"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "def plot_reconstructed_images(tensor, labels):\n",
        "\n",
        "    \n",
        "    if len(tensor.shape) == 2 and tensor.shape[1] ==  args['in_size']**2:\n",
        "     \n",
        "        images = tensor.reshape(-1, 1, args['in_size'], args['in_size']).detach().cpu().numpy()\n",
        "    elif len(tensor.shape) == 4 and tensor.shape[1:] == (1, args['in_size'], args['in_size']):\n",
        "       \n",
        "        images = tensor.detach().cpu().numpy()\n",
        "    else:\n",
        "        raise ValueError(\"Unexpected image shape\")\n",
        "\n",
        "    num_images = len(labels)\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(num_images * 2, 2))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        if num_images == 1:\n",
        "            ax = axes\n",
        "        else:\n",
        "            ax = axes[i]\n",
        "        ax.imshow(images[i, 0], cmap='gray')\n",
        "        ax.set_title(f\"Label: {labels[i]}\")\n",
        "        ax.axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlrOiNiMAhRC"
      },
      "source": [
        "## Class incremental model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9H-N68w6AhRC"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Agent:\n",
        "    def __init__(self, args, train_datasets, val_datasets):\n",
        "        self.args = args\n",
        "        self.dev = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        self.current_scholar = Scholar(self.args).to(self.dev)\n",
        "        self.discriminator = Discriminator(img_shape=(args['in_size'], args['in_size'], args['n_channels'])).to(self.dev)\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "        self.adversarial_loss = torch.nn.BCELoss()\n",
        "        self.reset_acc()\n",
        "        self.train_datasets = train_datasets\n",
        "        self.val_datasets = val_datasets\n",
        "        self.r = self.args['ratio']\n",
        "\n",
        "        print(f\"Total number of parameters MLP: {get_n_params(self.current_scholar.solver)}\")\n",
        "        tot_params = get_n_params(self.current_scholar.solver) + get_n_params(self.current_scholar.generator) + get_n_params(self.discriminator)\n",
        "        print(f\"Total number of parameters: {tot_params}\")\n",
        "\n",
        "\n",
        "    def reset_acc(self):\n",
        "        self.acc = {key: [] for key in self.args['task_names']}\n",
        "        self.acc_end = {key: [] for key in self.args['task_names']}\n",
        "\n",
        "\n",
        "\n",
        "    def train_solver(self, X, y):\n",
        "\n",
        "        # print(f\"Training Solver in task n°{task_n}.......\\n\")\n",
        "\n",
        "        output = self.current_scholar.solver(X)\n",
        "        loss = self.criterion(output, y)\n",
        "\n",
        "        return loss, output\n",
        "\n",
        "    def use_generator(self, num_samples, y, gen_images = False):\n",
        "      z = torch.randn(num_samples, self.args['g_input_dim']).to(self.dev)\n",
        "\n",
        "      gen_input = self.old_scholar.generator(z)\n",
        "\n",
        "      output = self.current_scholar.solver(gen_input) # We train the model on old samples.\n",
        "\n",
        "      if gen_images:\n",
        "\n",
        "        unique_labels, indices = torch.unique(y, return_inverse=True)\n",
        "        sample_indices = [indices.tolist().index(i) for i in range(len(unique_labels))]\n",
        "        tensor_to_plot = gen_input[sample_indices]\n",
        "        if gen_input[sample_indices].shape[1] == self.args['in_size']:\n",
        "            tensor_to_plot = torch.permute(gen_input[sample_indices], (0, 3, 1, 2))\n",
        "        \n",
        "\n",
        "        plot_reconstructed_images(tensor_to_plot, list(unique_labels))\n",
        "\n",
        "      y_ = F.softmax(self.old_scholar.solver(gen_input), dim = -1)\n",
        "      y_ = torch.argmax(y_, dim = -1)\n",
        "      \n",
        "      \n",
        "      loss = self.criterion(output, y_)\n",
        "      return loss\n",
        "      \n",
        "    def train_generator(self, task, task_loader):\n",
        "\n",
        "        optimizer_G = torch.optim.Adam(self.current_scholar.generator.parameters(), lr=self.args['lr_generator'])\n",
        "        optimizer_D = torch.optim.Adam(self.discriminator.parameters(), lr=self.args['lr_discriminator'])\n",
        "\n",
        "        for epoch in range(self.args['epochs_gan']):\n",
        "            for i, (imgs, _) in enumerate(task_loader):\n",
        "                batch_size = imgs.size(0)\n",
        "\n",
        "                valid = torch.ones(batch_size, 1, requires_grad=False)\n",
        "                fake = torch.zeros(batch_size, 1, requires_grad=False)\n",
        "                if torch.cuda.is_available():\n",
        "                    valid, fake = valid.cuda(), fake.cuda()\n",
        "\n",
        "                real_imgs = imgs\n",
        "                if torch.cuda.is_available():\n",
        "                    real_imgs = real_imgs.cuda()\n",
        "\n",
        "                optimizer_G.zero_grad()\n",
        "                z = torch.randn(batch_size, self.args['g_input_dim'])\n",
        "                if torch.cuda.is_available():\n",
        "                    z = z.cuda()\n",
        "                gen_imgs = self.current_scholar.generator(z)\n",
        "                g_loss = self.adversarial_loss(self.discriminator(gen_imgs), valid)\n",
        "                g_loss.backward()\n",
        "                optimizer_G.step()\n",
        "\n",
        "                optimizer_D.zero_grad()\n",
        "                real_loss = self.adversarial_loss(self.discriminator(real_imgs), valid)\n",
        "                fake_loss = self.adversarial_loss(self.discriminator(gen_imgs.detach()), fake)\n",
        "                d_loss = (real_loss + fake_loss) / 2\n",
        "                d_loss.backward()\n",
        "                optimizer_D.step()\n",
        "\n",
        "            print(f\"Task {task} | Epoch {epoch} | D loss: {d_loss.item()} | G loss: {g_loss.item()}\")\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        for i, (task, data) in enumerate(self.train_datasets.items()):\n",
        "            print(task)\n",
        "            set_random_seed(42)\n",
        "            print(f\"Solving task n°{i+1}\")\n",
        "            self.current_scholar = Scholar(self.args)\n",
        "            if torch.cuda.is_available():\n",
        "                self.current_scholar.solver.cuda()\n",
        "                self.current_scholar.generator.cuda()\n",
        "\n",
        "            optimizer = torch.optim.Adam(self.current_scholar.solver.parameters(), lr=self.args['lr'])\n",
        "\n",
        "            loader = torch.utils.data.DataLoader(data, batch_size=self.args['bs'], shuffle=True)\n",
        "\n",
        "            gen_images = True\n",
        "            self.train_generator(i, loader)\n",
        "            for epoch in range(self.args['epochs']):\n",
        "\n",
        "              total = 0\n",
        "              correct = 0\n",
        "              loss_current_data = 0\n",
        "              loss_past_data = 0\n",
        "              max_num_samples = self.r * len(data)\n",
        "              n_samples = 0\n",
        "              for e1, (X, y) in enumerate(loader):\n",
        "                  if torch.cuda.is_available():\n",
        "                      X, y = X.cuda(), y.cuda()\n",
        "                  n_samples += X.shape[0]\n",
        "                  \n",
        "                  inter_loss, output = self.train_solver(X, y)\n",
        "                  loss_current_data += inter_loss\n",
        "\n",
        "                  correct += torch.sum(torch.topk(output, axis=1, k=1)[1].squeeze(1) == y)\n",
        "                  total += len(X)\n",
        "                  acc_train = correct/total\n",
        "\n",
        "                  if n_samples < max_num_samples and i != 0:\n",
        "                    \n",
        "                    loss_past_data += self.use_generator(n_samples, y, gen_images = gen_images) # Loss from generated samples of previous tasks.\n",
        "                    if gen_images:\n",
        "                      gen_images = False\n",
        "\n",
        "                  \n",
        "\n",
        "\n",
        "              print(f\"Epoch {epoch}: Loss current data{loss_current_data/(e1+1):.3f} Loss past data {loss_past_data/(e1+1):.3f} Acc: {acc_train:.3f}\")\n",
        "\n",
        "              \n",
        "\n",
        "              tot_loss = self.r * loss_current_data + (1-self.r) * loss_past_data\n",
        "              optimizer.zero_grad()\n",
        "              tot_loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "            self.validate(end_of_epoch=True)\n",
        "\n",
        "            self.old_scholar = deepcopy(self.current_scholar)\n",
        "\n",
        "            del self.current_scholar\n",
        "\n",
        "            for param in self.old_scholar.solver.parameters():\n",
        "              param.requires_grad = False\n",
        "\n",
        "            for param in self.old_scholar.generator.parameters():\n",
        "              param.requires_grad = False\n",
        "            \n",
        "            self.old_scholar.eval()\n",
        "\n",
        "            # ...\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, end_of_epoch=False):\n",
        "        self.current_scholar.solver.eval()\n",
        "        for task, data in self.val_datasets.items():\n",
        "            loader = torch.utils.data.DataLoader(data, batch_size=args['bs'], shuffle=True)\n",
        "            correct, total = 0, 0\n",
        "            for e, (X, y) in enumerate(loader):\n",
        "                if torch.cuda.is_available():\n",
        "                    X, y = X.cuda(), y.cuda()\n",
        "                output = self.current_scholar.solver(X)\n",
        "                correct += torch.sum(torch.topk(output, axis=1, k=1)[1].squeeze(1) == y).item()\n",
        "                total += len(X)\n",
        "            self.acc[task].append(correct/total)\n",
        "            if end_of_epoch:\n",
        "                self.acc_end[task].append(correct/total)\n",
        "        self.current_scholar.solver.train()\n",
        "        self.current_scholar.generator.train()\n",
        "\n",
        "    \n",
        "class Solver(torch.nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "        hidden_size = args['hidden_size']\n",
        "        self.fc1 = torch.nn.Linear(args['in_size']**2 * args['n_channels'], hidden_size)\n",
        "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = torch.nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc4 = torch.nn.Linear(hidden_size, args['num_classes'])\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = input.flatten(start_dim=1)\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        x = torch.nn.functional.relu(self.fc2(x))\n",
        "        x = torch.nn.functional.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "    \n",
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self, latent_dim, img_shape):\n",
        "        super(Generator, self).__init__()\n",
        "        self.img_shape = img_shape\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(latent_dim, 128),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(128, 256),\n",
        "            torch.nn.BatchNorm1d(256, 0.8),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 512),\n",
        "            torch.nn.BatchNorm1d(512, 0.8),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, int(np.prod(img_shape))),\n",
        "            torch.nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.size(0), *self.img_shape)\n",
        "        return img\n",
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, img_shape):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            torch.nn.Linear(int(np.prod(img_shape)), 512),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(512, 256),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(256, 1),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity\n",
        "\n",
        "    \n",
        "class Scholar(nn.Module):\n",
        "  def __init__(self, args):\n",
        "    super(Scholar, self).__init__()\n",
        "    self.solver = Solver(args)\n",
        "    self.generator = Generator(latent_dim = args['g_input_dim'], img_shape=(args['in_size'], args['in_size'], args['n_channels']))\n",
        "\n",
        "\n",
        "  def forward(self, x, mode = 'solver'):\n",
        "\n",
        "    if mode == 'solver':\n",
        "      out = self.solver(x)\n",
        "\n",
        "\n",
        "    return out\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "\n",
        "def get_gpu_usage():\n",
        "    try:\n",
        "        # Run the nvidia-smi command\n",
        "        result = subprocess.check_output(['nvidia-smi', '--query-gpu=utilization.gpu,memory.total,memory.used,memory.free', '--format=csv,nounits,noheader'])\n",
        "        result = result.decode('utf-8').strip()\n",
        "        \n",
        "        # Split the output into lines and parse each line\n",
        "        gpu_usages = []\n",
        "        for line in result.split('\\n'):\n",
        "            gpu_utilization, total_memory, used_memory, free_memory = map(int, line.split(', '))\n",
        "            gpu_usages.append({\n",
        "                'gpu_utilization': gpu_utilization,\n",
        "                'total_memory': total_memory,\n",
        "                'used_memory': used_memory,\n",
        "                'free_memory': free_memory\n",
        "            })\n",
        "        \n",
        "        # Print or return the parsed information\n",
        "        for i, usage in enumerate(gpu_usages):\n",
        "            print(f\"GPU {i}:\")\n",
        "            print(f\"  Utilization: {usage['gpu_utilization']}%\")\n",
        "            print(f\"  Total Memory: {usage['total_memory']} MB\")\n",
        "            print(f\"  Used Memory: {usage['used_memory']} MB\")\n",
        "            print(f\"  Free Memory: {usage['free_memory']} MB\")\n",
        "        \n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"Failed to run nvidia-smi: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZGNUwlGAhRC"
      },
      "outputs": [],
      "source": [
        "classes = list(range(args['num_classes']))\n",
        "set_random_seed(42)\n",
        "shuffle(classes)\n",
        "class_split = {str(i): classes[i*2: (i+1)*2] for i in range(args['num_tasks'])}\n",
        "args['task_names'] = list(class_split.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W8dV33YgAhRC",
        "outputId": "0f505312-ba2b-4319-c7b0-74f94de95b11"
      },
      "outputs": [],
      "source": [
        "train, test = get_dataset(dataroot='../data/', dataset=args['dataset'])\n",
        "train_tasks = split_dataset(train, class_split)\n",
        "val_tasks = split_dataset(test, class_split)\n",
        "agent = Agent(args, train_tasks, val_tasks)\n",
        "\n",
        "agent.validate()\n",
        "random_model_acc = [i[0] for i in agent.acc.values()]\n",
        "agent.reset_acc()\n",
        "agent.train()\n",
        "\n",
        "acc_at_end_arr = dict2array(agent.acc_end)\n",
        "plot_accuracy_matrix(acc_at_end_arr)\n",
        "\n",
        "acc_arr = dict2array(agent.acc)\n",
        "plot_acc_over_time(acc_arr)\n",
        "\n",
        "print(f\"The average accuracy at the end of sequence is: {compute_average_accuracy(acc_at_end_arr):.3f}\")\n",
        "print(f\"BWT:'{compute_backward_transfer(acc_at_end_arr):.3f}'\")\n",
        "print(f\"FWT:'{compute_forward_transfer(acc_at_end_arr, random_model_acc):.3f}'\")\n",
        "get_gpu_usage()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
